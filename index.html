<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Mining Exam Notes (Dark Mode)</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- KaTeX CSS for rendering formulas -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" crossorigin="anonymous">
    <style>
        /* Custom Styles for Formula Blocks, Print, and Layout Overrides */
        body {
            font-family: 'Inter', sans-serif;
            -webkit-tap-highlight-color: transparent;
            color: #E5E7EB; /* Default light gray text */
        }
        .header {
            /* Setting a fixed height for a consistent visual top bar */
            height: 64px; 
            line-height: 64px;
            padding: 0 1rem;
        }

        .question-content {
            transition: max-height 0.3s ease-in-out, padding 0.3s ease-in-out;
            overflow: hidden;
            max-height: 2000px; /* Arbitrarily large for expansion */
        }
        .collapsed .question-content {
            max-height: 0;
            padding-top: 0;
            padding-bottom: 0;
        }
        .highlight {
            background-color: #fce303; /* Bright yellow highlight */
            color: #0a0a0a;
            font-weight: bold;
        }
        
        /* Key terms in dark mode */
        .key-term {
            color: #00bcd4; /* Bright cyan accent for key terms */
            font-weight: 600;
        }
        
        /* KaTeX styling to ensure high contrast in dark mode */
        .katex-display {
            padding: 1rem;
            margin: 1rem 0;
            background-color: #1f2937; /* Dark gray for formula blocks */
            border-radius: 0.5rem;
            overflow-x: auto;
            color: #E5E7EB;
        }

        /* Table styling for dark mode */
        .min-w-full th, .min-w-full td {
            border-color: #374151 !important;
        }
        .min-w-full thead tr {
            background-color: #1f2937;
        }
        .min-w-full tbody tr:nth-child(even) {
            background-color: #111827; /* Dark stripe */
        }
        .min-w-full tbody tr:nth-child(odd) {
            background-color: #0a0a0a; /* True black background */
        }

        /* Print Styles: Retain high contrast, but use white paper */
        @media print {
            .header, .toc-controls, .action-bar {
                display: none !important;
            }
            body, .question-card, .question-content {
                background-color: white !important;
                color: #000 !important;
            }
            .question-card {
                box-shadow: none !important;
                border: 1px solid #ccc !important;
                margin-bottom: 0.5rem !important;
                border-radius: 0 !important;
                page-break-inside: avoid;
            }
            .question-content {
                max-height: none !important;
                padding: 0.5rem !important;
            }
            .key-term {
                color: #d9534f; /* Reset key term color for print */
            }
            table, th, td {
                border-color: #000 !important;
            }
        }
    </style>
</head>
<body class="bg-gray-950">

    <!-- Sticky Header (top-0 z-20) -->
    <header class="header sticky top-0 bg-gray-900 text-white shadow-xl z-20">
        <h1 class="text-xl font-bold text-center">Data Mining Exam Notes</h1>
    </header>

    <main class="container mx-auto p-4 lg:p-6">
        
        <!-- Controls & TOC (NO STICKY CLASSES HERE) -->
        <div class="toc-controls bg-gray-900 p-4 mb-4 rounded-lg shadow-2xl space-y-4 border border-gray-800">
            
            <div class="flex flex-col sm:flex-row gap-3">
                <input type="text" id="search-input" placeholder="Search and highlight text..." 
                       class="flex-grow p-2 bg-gray-800 text-white border border-gray-700 rounded-lg text-sm focus:ring-blue-500 focus:border-blue-500" 
                       oninput="highlightText(this.value)">
                <button onclick="window.print()" class="print-btn w-full sm:w-auto px-4 py-2 bg-blue-700 text-white rounded-lg shadow-lg hover:bg-blue-600 transition">
                    Print Notes
                </button>
            </div>

            <nav>
                <ul id="toc" class="flex flex-wrap justify-center sm:justify-start gap-2 border-t border-gray-700 pt-3 mt-3">
                    <!-- TOC links generated by JS -->
                </ul>
            </nav>
        </div>

        <!-- Main Content Section -->
        <section id="notes-container" class="space-y-4">
            
            <!-- Question 1 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-xl border border-gray-800" id="q1">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q1">
                    <h2 class="question-title text-base font-semibold text-blue-300">1. Explain the Naïve Bayes Classifier with a suitable example. Discuss its advantages and limitations.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="text-sm">The Naïve Bayes Classifier is a probabilistic classification algorithm based on Bayes’ Theorem. It operates under the <strong class="key-term">naïve assumption</strong> that the presence of a particular feature in a class is independent of the presence of any other feature, given the class variable.</p>
                        <p class="font-bold text-base mt-3 mb-1 text-blue-400">Bayes' Theorem:</p>
                        $$P(C|X) = \frac{P(X|C)P(C)}{P(X)}$$
                        <p class="mt-2 text-sm">Where:</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li>$P(C|X)$: Posterior probability (the probability of class $C$ given input data $X$).</li>
                            <li>$P(X|C)$: Likelihood (the probability of data $X$ given class $C$).</li>
                            <li>$P(C)$: Prior probability (the probability of class $C$).</li>
                            <li>$P(X)$: Predictor prior probability (the probability of data $X$).</li>
                        </ul>
                        <p class="font-bold text-base mt-3 mb-1 text-blue-400">Example (Classification of a fruit as 'Banana' or 'Orange'):</p>
                        <p class="text-sm">Suppose a fruit has features $X = \{ \text{Long}, \text{Sweet}, \text{Yellow} \}$.
                        The classifier calculates the posterior probability for each class ($C_1=\text{Banana}, C_2=\text{Orange}$) using the naive assumption:</p>
                        $$P(C|X) \propto P(C) \times P(\text{Long}|C) \times P(\text{Sweet}|C) \times P(\text{Yellow}|C)$$
                        <p class="text-sm">The fruit is assigned to the class with the highest posterior probability.</p>
                        <p class="font-bold text-base mt-4 mb-1 text-green-400">Advantages:</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Simple and Fast:</strong> Easy to implement and computationally efficient.</li>
                            <li><strong class="key-term">Scalability:</strong> Requires a small amount of training data to estimate the necessary parameters.</li>
                            <li><strong class="key-term">Good Performance:</strong> Often performs well in text classification and multi-class prediction problems due to its robust handling of high-dimensional data.</li>
                        </ul>
                        <p class="font-bold text-base mt-4 mb-1 text-red-400">Limitations:</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Conditional Independence Assumption:</strong> The "naïve" assumption that all features are independent is rarely true in real-world data, which can lead to prediction inaccuracies.</li>
                            <li><strong class="key-term">Zero Frequency Problem:</strong> If a categorical feature value does not appear in the training data for a class, the likelihood $P(X|C)$ will be zero, causing the entire posterior probability for that class to become zero. (Handled typically by Laplace smoothing).</li>
                        </ul>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(1)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 2 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q2">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q2">
                    <h2 class="question-title text-base font-semibold text-blue-300">2. Explain the k-Nearest Neighbor (k-NN) algorithm for classification. How is the value of k chosen?</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">k-Nearest Neighbor (k-NN) Algorithm</p>
                        <p class="text-sm">The k-NN algorithm is a <strong class="key-term">non-parametric, lazy learning</strong> classification method. It classifies a new data point (query point) based on the majority class among its 'k' closest neighbors in the feature space.</p>
                        <p class="font-bold text-sm mt-3 mb-1 text-blue-400">Process:</p>
                        <ol class="list-decimal ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Distance Calculation:</strong> Calculate the distance (e.g., Euclidean, Manhattan) between the new query point and all points in the training dataset.</li>
                            <li><strong class="key-term">Neighbor Selection:</strong> Select the $k$ training samples that are closest to the new query point based on the calculated distances.</li>
                            <li><strong class="key-term">Classification:</strong> Assign the query point to the class that is most frequent (majority vote) among its $k$ nearest neighbors. In case of ties, different tie-breaking rules can be used.</li>
                        </ol>
                        <p class="font-bold text-base mt-4 mb-1 text-blue-400">Choosing the Value of $k$</p>
                        <p class="text-sm">The value of $k$ is a crucial hyperparameter, typically chosen through <strong class="key-term">empirical testing</strong> (cross-validation) on the training data.</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Small $k$:</strong> Low bias, high variance. The model is highly susceptible to noise (outliers) and leads to a complex decision boundary (overfitting).</li>
                            <li><strong class="key-term">Large $k$:</strong> High bias, low variance. The model tends to smooth out the decision boundary and may lead to underfitting (losing local characteristics).</li>
                        </ul>
                        <p class="font-bold text-sm mt-3 mb-1 text-blue-400">Optimal $k$ Selection:</p>
                        <ol class="list-decimal ml-5 space-y-1 text-sm">
                            <li>Often, $k$ is chosen as an odd number to prevent ties in binary classification.</li>
                            <li>The optimal value is determined by selecting a range of $k$ values and evaluating the classifier's performance (e.g., accuracy) using cross-validation. The $k$ that yields the best performance on the validation set is selected.</li>
                        </ol>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(2)">Copy Answer</button>
                    </div>
                </div>
            </article>
            
            <!-- Question 3 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q3">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q3">
                    <h2 class="question-title text-base font-semibold text-blue-300">3. Define Association Rule Mining. Clearly explain the terms Support and Confidence with mathematical formulas and an example.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">Association Rule Mining</p>
                        <p class="text-sm">Association Rule Mining is a technique used to find frequent patterns, associations, correlations, or causal structures among sets of items or objects in transaction databases, relational databases, and other information repositories. It aims to discover rules of the form $A \Rightarrow B$, meaning that transactions containing itemset $A$ tend to also contain itemset $B$.</p>
                        <h4 class="font-bold text-sm mt-3 mb-1 text-blue-400">Terms:</h4>
                        <p class="font-bold text-sm mt-3 mb-1 text-gray-400">A. Support ($S$)</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Definition:</strong> Support is an indication of how frequently the itemset appears in the database.</li>
                            <li><strong class="key-term">Formula:</strong> The support for an itemset $A \Rightarrow B$ is the proportion of total transactions $T$ that contain both $A$ and $B$.</li>
                        </ul>
                        $$Support(A \Rightarrow B) = Support(A \cup B) = \frac{\text{Number of transactions containing } A \cup B}{\text{Total number of transactions}}$$
                        <p class="font-bold text-sm mt-4 mb-1 text-gray-400">B. Confidence ($C$)</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Definition:</strong> Confidence is an indication of the number of times the rule $A \Rightarrow B$ has been found to be true (i.e., the probability that $B$ appears given that $A$ has already appeared).</li>
                            <li><strong class="key-term">Formula:</strong></li>
                        </ul>
                        $$Confidence(A \Rightarrow B) = P(B|A) = \frac{\text{Support}(A \cup B)}{\text{Support}(A)} = \frac{\text{Number of transactions containing } A \cup B}{\text{Number of transactions containing } A}$$
                        <p class="font-bold text-sm mt-4 mb-1 text-blue-400">Example (Transaction Database):</p>
                        <div class="overflow-x-auto">
                            <table class="min-w-full text-sm">
                                <thead>
                                    <tr class="bg-gray-700">
                                        <th class="p-2 text-center">Transaction ID</th>
                                        <th class="p-2 text-center">Items Bought</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="border-b">
                                        <td class="p-2 text-center">1</td>
                                        <td class="p-2 text-center">{Milk, Bread}</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2 text-center">2</td>
                                        <td class="p-2 text-center">{Bread, Diapers, Beer}</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2 text-center">3</td>
                                        <td class="p-2 text-center">{Milk, Diapers, Soda}</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2 text-center">4</td>
                                        <td class="p-2 text-center">{Bread, Milk, Diapers, Beer}</td>
                                    </tr>
                                    <tr>
                                        <td class="p-2 text-center">5</td>
                                        <td class="p-2 text-center">{Bread, Milk, Diapers, Soda}</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <p class="text-sm"><em>Total Transactions = 5</em></p>
                        <ul class="list-disc ml-5 space-y-1 text-sm mt-2">
                            <li><strong class="key-term">Rule:</strong> $\{\text{Bread}\} \Rightarrow \{\text{Milk}\}$</li>
                            <li><strong class="key-term">Support:</strong> Transactions containing $\{\text{Bread}, \text{Milk}\}$ are 1, 4, 5 (3 transactions).</li>
                        </ul>
                        $$\text{Support}(\{\text{Bread}\} \Rightarrow \{\text{Milk}\}) = \frac{3}{5} = 0.6 \text{ (60\%)}$$
                        <ul class="list-disc ml-5 space-y-1 text-sm mt-2">
                            <li><strong class="key-term">Confidence:</strong> Transactions containing $\{\text{Bread}\}$ are 1, 2, 4, 5 (4 transactions).</li>
                        </ul>
                        $$\text{Confidence}(\{\text{Bread}\} \Rightarrow \{\text{Milk}\}) = \frac{\text{Support}(\{\text{Bread}, \text{Milk}\})}{\text{Support}(\{\text{Bread}\})} = \frac{3/5}{4/5} = \frac{3}{4} = 0.75 \text{ (75\%)}$$
                        <p class="text-sm mt-2">This means 75% of customers who buy Bread also buy Milk.</p>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(3)">Copy Answer</button>
                    </div>
                </div>
            </article>
            
            <!-- Question 4 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q4">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q4">
                    <h2 class="question-title text-base font-semibold text-blue-300">4. Explain the Apriori algorithm for finding frequent itemsets. Illustrate the candidate generation and pruning steps.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">Apriori Algorithm</p>
                        <p class="text-sm">The Apriori algorithm is an influential algorithm for mining frequent itemsets (those whose support is greater than or equal to a minimum support threshold, $\text{min\_sup}$). It uses a prior knowledge property (the <strong class="key-term">Apriori property</strong>) to efficiently prune the search space.</p>
                        <p class="font-bold text-sm mt-3 mb-1 text-blue-400">Apriori Property (Anti-monotone Property):</p>
                        <p class="text-sm">If an itemset is frequent, then all of its subsets must also be frequent. Conversely, if any subset of a candidate itemset is infrequent, then the candidate itemset itself cannot be frequent and can be safely pruned.</p>
                        <p class="font-bold text-sm mt-3 mb-1 text-blue-400">Steps:</p>
                        <ol class="list-decimal ml-5 space-y-2 text-sm">
                            <li><strong class="key-term">Join Step (Candidate Generation):</strong>
                                <ul class="list-disc ml-5 mt-1 space-y-1">
                                    <li>The set of frequent $k$-itemsets ($L_k$) is used to generate the set of candidate $(k+1)$-itemsets ($C_{k+1}$).</li>
                                    <li>$C_{k+1}$ is generated by joining $L_k$ with itself, where two $k$-itemsets are joinable if their first $k-1$ items are the same.</li>
                                    <li>*Example:* If $L_2 = \{\{1,2\}, \{1,3\}, \{2,3\}\}$, the join step generates $C_3 = \{\{1,2,3\}\}$.</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Prune Step (Candidate Pruning):</strong>
                                <ul class="list-disc ml-5 mt-1 space-y-1">
                                    <li>The Apriori property is applied to prune (eliminate) any candidate itemset $c \in C_{k+1}$ that has at least one <strong>infrequent $k$-subset</strong>.</li>
                                    <li>If any subset of a generated candidate is not found in the frequent $k$-itemset list ($L_k$), the candidate is immediately removed from $C_{k+1}$ without needing to scan the database.</li>
                                    <li>*Example:* If $C_4 = \{\{1,2,3,4\}\}$ is generated, but the $3$-itemset subset $\{1,2,4\}$ was not found in $L_3$ (i.e., it was infrequent), then $\{1,2,3,4\}$ is pruned from $C_4$.</li>
                                </ul>
                            </li>
                        </ol>
                        <ol class="list-decimal ml-5 space-y-2 text-sm" start="3">
                            <li><strong class="key-term">Support Counting:</strong> The support of the remaining candidates in $C_{k+1}$ is counted by scanning the database.</li>
                            <li><strong class="key-term">Selection:</strong> Itemsets in $C_{k+1}$ meeting the $\text{min\_sup}$ threshold are kept to form the frequent itemset $L_{k+1}$.</li>
                            <li><strong class="key-term">Iteration:</strong> The process repeats until no more frequent itemsets can be found.</li>
                        </ol>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(4)">Copy Answer</button>
                    </div>
                </div>
            </article>
            
            <!-- Question 5 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q5">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q5">
                    <h2 class="question-title text-base font-semibold text-blue-300">5. Define Cluster Analysis. Explain the requirement of an effective clustering method.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">Cluster Analysis (Clustering)</p>
                        <p class="text-sm">Cluster Analysis is a descriptive, unsupervised data mining task that groups a set of data objects into multiple groups (clusters) such that objects within the same cluster have <strong class="key-term">high similarity</strong> to one another, and objects in different clusters have <strong class="key-term">low similarity</strong>. Similarity is often measured by distance metrics (e.g., Euclidean distance).</p>
                        <p class="font-bold text-base mt-4 mb-1 text-blue-400">Requirement of an Effective Clustering Method:</p>
                        <ol class="list-decimal ml-5 space-y-2 text-sm">
                            <li><strong class="key-term">Scalability:</strong> Ability to handle large databases with millions of data objects efficiently and quickly.</li>
                            <li><strong class="key-term">Ability to Deal with Different Attribute Types:</strong> Capability to handle various data types, including numerical, categorical, and binary.</li>
                            <li><strong class="key-term">Discovery of Clusters with Arbitrary Shape:</strong> Capability to find clusters of complex shapes (e.g., non-convex, elongated) beyond just spherical or circular shapes.</li>
                            <li><strong class="key-term">Minimal Requirement for Domain Knowledge to Determine Parameters:</strong> The method should not require excessive prior knowledge or guesswork to set input parameters (like $k$ in k-Means).</li>
                            <li><strong class="key-term">Ability to Handle Noise and Outliers:</strong> Robustness against noisy data and the ability to detect and either ignore or properly handle outliers.</li>
                            <li><strong class="key-term">Insensitivity to Order of Input Records:</strong> The quality of the clustering should not depend on the order in which the data is presented.</li>
                            <li><strong class="key-term">Interpretability and Usability:</strong> The resulting clusters should be meaningful, understandable, and useful for the user's specific application.</li>
                        </ol>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(5)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 6 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q6">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q6">
                    <h2 class="question-title text-base font-semibold text-blue-300">6. What is Classification in Data Mining? Differentiate between Classification and Prediction.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">Classification in Data Mining</p>
                        <p class="text-sm">Classification is a <strong class="key-term">supervised learning task</strong> that maps data items into predefined class labels (categories). It is a two-step process:</p>
                        <ol class="list-decimal ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Learning/Training:</strong> A classifier is built by analyzing a training set of data tuples (records) with known class labels.</li>
                            <li><strong class="key-term">Classification/Prediction:</strong> The trained classifier is used to predict the class label for new, unlabeled data tuples. The goal is to accurately assign the new data to one of the existing classes.</li>
                        </ol>
                        <p class="font-bold text-base mt-4 mb-1 text-blue-400">Differentiation between Classification and Prediction:</p>
                        <div class="overflow-x-auto">
                            <table class="min-w-full text-sm">
                                <thead>
                                    <tr class="bg-gray-700">
                                        <th class="p-2">Feature</th>
                                        <th class="p-2">Classification</th>
                                        <th class="p-2">Prediction</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Output Type</strong></td>
                                        <td class="p-2">Discrete/Categorical class labels.</td>
                                        <td class="p-2">Continuous/Numeric values.</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Goal</strong></td>
                                        <td class="p-2">To determine <em>what class</em> a data item belongs to.</td>
                                        <td class="p-2">To determine <em>what value</em> a data item has.</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Example Task</strong></td>
                                        <td class="p-2">Identifying if a transaction is <strong>'Fraudulent'</strong> or <strong>'Legitimate'</strong>.</td>
                                        <td class="p-2">Forecasting the <strong>'Selling Price'</strong> of a house or the <strong>'Rainfall Amount'</strong>.</td>
                                    </tr>
                                    <tr>
                                        <td class="p-2"><strong>Method</strong></td>
                                        <td class="p-2">Rule-based systems, Decision Trees, Naïve Bayes, k-NN.</td>
                                        <td class="p-2">Regression analysis (Linear, Multiple, Non-linear).</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(6)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 7 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q7">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q7">
                    <h2 class="question-title text-base font-semibold text-blue-300">7. Explain the Decision Tree Induction algorithm for classification. What is Information Gain and how is it used for attribute selection?</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">Decision Tree Induction Algorithm</p>
                        <p class="text-sm">Decision Tree Induction is a non-parametric classification method that generates a tree-like structure where:</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li>Each internal node represents a <strong class="key-term">test on an attribute</strong>.</li>
                            <li>Each branch represents an <strong class="key-term">outcome of the test</strong>.</li>
                            <li>Each leaf node holds a <strong class="key-term">class label</strong>.</li>
                        </ul>
                        <p class="font-bold text-sm mt-3 mb-1 text-blue-400">Algorithm Outline (Top-down, Recursive):</p>
                        <ol class="list-decimal ml-5 space-y-1 text-sm">
                            <li>The tree starts as a single node (the root) representing the entire training dataset.</li>
                            <li>If all samples in the current node belong to the same class, the node becomes a leaf and is labeled with that class.</li>
                            <li>Otherwise, the <strong class="key-term">best attribute</strong> is selected to partition the samples into individual subsets. (The "best" attribute is chosen using a metric like Information Gain).</li>
                            <li>A branch is created for each outcome of the test on the chosen attribute.</li>
                            <li>The process is repeated recursively for each resulting subset until a stopping condition is met (e.g., all samples belong to the same class, no remaining attributes, or maximum depth reached).</li>
                        </ol>
                        
                        <p class="font-bold text-base mt-4 mb-1 text-blue-400">Information Gain</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Definition:</strong> Information Gain (IG) measures the expected reduction in entropy caused by partitioning the data based on an attribute. It represents how much uncertainty about the class label is reduced by knowing the value of that attribute.</li>
                            <li><strong class="key-term">Formula:</strong></li>
                        </ul>
                        $$\text{Gain}(A) = \text{Info}(D) - \text{Info}_A(D)$$
                        <p class="mt-2 text-sm">Where:</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li>$\text{Info}(D)$ is the required average information (entropy) to classify a tuple in data set $D$.</li>
                            <li>$\text{Info}_A(D)$ is the expected information required to classify a tuple from $D$ after partitioning by attribute $A$.</li>
                        </ul>
                        <p class="font-bold text-sm mt-4 mb-1 text-blue-400">Use for Attribute Selection:</p>
                        <p class="text-sm">Information Gain is the primary metric used in algorithms like ID3 (and its derivatives) for <strong class="key-term">attribute selection</strong>. At each step of the tree induction, the algorithm calculates the Information Gain for <em>every</em> available attribute and <strong class="key-term">selects the attribute that yields the highest Information Gain</strong> as the splitting criterion for the current node. This attribute creates the purest (most homogenous) partition of the data with respect to class labels.</p>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(7)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 8 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q8">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q8">
                    <h2 class="question-title text-base font-semibold text-blue-300">8. Write short notes on the following clustering algorithms for large databases: a. BIRCH b. DBSCAN</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-sm mt-1 mb-1 text-gray-400">a. BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies)</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Purpose:</strong> Designed for clustering large datasets by summarizing the data into a more compact structure.</li>
                            <li><strong class="key-term">Structure:</strong> It uses a <strong class="key-term">Clustering Feature (CF) tree</strong>—a height-balanced tree structure that stores summary statistics for subclusters. A CF is a three-dimensional vector $(N, \text{LS}, \text{SS})$, where $N$ is the number of data points, $\text{LS}$ is the linear sum, and $\text{SS}$ is the square sum of the data points.</li>
                            <li><strong class="key-term">Process:</strong> BIRCH performs clustering in a single scan of the dataset. It builds the CF tree dynamically as data points are inserted, effectively reducing the original dataset size. A global clustering algorithm (like k-Means) is then optionally applied to the leaf nodes of the CF tree.</li>
                            <li><strong class="key-term">Key Advantage:</strong> Highly efficient and scalable for large, high-dimensional data; incremental clustering possible.</li>
                        </ul>
                        <p class="font-bold text-sm mt-4 mb-1 text-gray-400">b. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><strong class="key-term">Purpose:</strong> A density-based clustering algorithm capable of finding arbitrarily shaped clusters and identifying outliers (noise).</li>
                            <li><strong class="key-term">Core Concept:</strong> DBSCAN groups together densely connected data points. It requires two parameters:
                                <ul class="list-disc ml-5 mt-1 space-y-1">
                                    <li>$\text{Eps}$ ($\epsilon$): The maximum radius of the neighborhood to consider.</li>
                                    <li>$\text{MinPts}$: The minimum number of points required to form a dense region.</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Point Types:</strong>
                                <ul class="list-disc ml-5 mt-1 space-y-1">
                                    <li><strong class="key-term">Core Point:</strong> A point with at least $\text{MinPts}$ neighbors within its $\epsilon$ radius.</li>
                                    <li><strong class="key-term">Border Point:</strong> A point within the $\epsilon$ neighborhood of a core point but is not a core point itself.</li>
                                    <li><strong class="key-term">Noise Point:</strong> A point that is neither a core point nor a border point.</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Process:</strong> It starts at an arbitrary, unvisited core point and retrieves all density-reachable points with respect to $\text{Eps}$ and $\text{MinPts}$. This forms a cluster. The process repeats until all points have been visited.</li>
                            <li><strong class="key-term">Key Advantage:</strong> Can discover clusters of arbitrary shape and is robust to noise/outliers.</li>
                        </ul>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(8)">Copy Answer</button>
                    </div>
                </div>
            </article>
            
            <!-- Question 9 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q9">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q9">
                    <h2 class="question-title text-base font-semibold text-blue-300">9. What are Association Rules? Define Support, Confidence, and Lift with examples.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">Association Rules</p>
                        <p class="text-sm">Association Rules are expressions of the form $A \Rightarrow B$, where $A$ and $B$ are sets of items (itemsets) and $A \cap B = \emptyset$. The rule means that if itemset $A$ occurs in a transaction, then itemset $B$ is likely to occur as well. They are typically generated after finding frequent itemsets based on minimum support and confidence thresholds.</p>
                        <p class="font-bold text-base mt-4 mb-1 text-blue-400">Definitions and Formulas:</p>
                        <ul class="list-disc ml-5 space-y-3 text-sm">
                            <li><strong class="key-term">Support ($S$)</strong>
                                <ul class="list-none ml-0 mt-1 space-y-1">
                                    <li><span class="font-semibold">Definition:</span> The proportion of transactions that contain both $A$ and $B$ (i.e., the frequency of the combined itemset $A \cup B$).</li>
                                    <li><span class="font-semibold">Formula:</span> $S(A \Rightarrow B) = P(A \cup B)$</li>
                                    <li><span class="font-semibold">Example:</span> If $\{\text{Laptop}, \text{Mouse}\}$ appears in 20 transactions (out of 100), $S = 20/100 = 0.2$.</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Confidence ($C$)</strong>
                                <ul class="list-none ml-0 mt-1 space-y-1">
                                    <li><span class="font-semibold">Definition:</span> The conditional probability that $B$ is in a transaction given that $A$ is in that transaction.</li>
                                    <li><span class="font-semibold">Formula:</span> $C(A \Rightarrow B) = P(B|A) = \frac{P(A \cup B)}{P(A)}$</li>
                                    <li><span class="font-semibold">Example:</span> If $S(\{\text{Laptop}, \text{Mouse}\}) = 0.2$ and $P(\text{Laptop}) = 0.4$, then $C = 0.2/0.4 = 0.5$.</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Lift ($L$)</strong>
                                <ul class="list-none ml-0 mt-1 space-y-1">
                                    <li><span class="font-semibold">Definition:</span> The ratio of the observed support of $A \cup B$ to the support expected if $A$ and $B$ were statistically independent. It measures the strength of the association, comparing the rule's confidence to the overall probability of $B$.</li>
                                    <li><span class="font-semibold">Formula:</span></li>
                                </ul>
                                $$L(A \Rightarrow B) = \frac{C(A \Rightarrow B)}{P(B)} = \frac{P(A \cup B)}{P(A)P(B)}$$
                                <ul class="list-none ml-0 mt-2 space-y-1">
                                    <li><span class="font-semibold">Interpretation:</span>
                                        <ul class="list-disc ml-5 space-y-1">
                                            <li>$L=1$: $A$ and $B$ are independent (no association).</li>
                                            <li>$L>1$: Positive correlation (the rule is useful).</li>
                                            <li>$L<1$: Negative correlation (the presence of $A$ makes $B$ less likely).</li>
                                        </ul>
                                    </li>
                                    <li><span class="font-semibold">Example:</span> If $P(\text{Mouse}) = 0.3$ and $C(\text{Laptop} \Rightarrow \text{Mouse}) = 0.5$, then $L = 0.5 / 0.3 \approx 1.67$. Since $L>1$, there is a strong positive association.</li>
                                </ul>
                            </li>
                        </ul>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(9)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 10 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q10">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q10">
                    <h2 class="question-title text-base font-semibold text-blue-300">10. List and briefly explain the major Issues in Data Mining.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">Major issues in data mining include:</p>
                        <ol class="list-decimal ml-5 space-y-2 text-sm">
                            <li><strong class="key-term">Mining Methodology and User Interaction:</strong>
                                <ul class="list-disc ml-5 mt-1 space-y-1">
                                    <li><span class="font-semibold">Mining Diverse Kinds of Knowledge:</span> Need to mine various data types and patterns (e.g., characterization, discrimination, association, classification, clustering).</li>
                                    <li><span class="font-semibold">Interactive Mining:</span> Allowing users to interact with the mining system to refine results and explore patterns.</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Performance Issues:</strong>
                                <ul class="list-disc ml-5 mt-1 space-y-1">
                                    <li><span class="font-semibold">Efficiency and Scalability:</span> Algorithms must be highly efficient and scalable to handle massive datasets.</li>
                                    <li><span class="font-semibold">Parallel, Distributed, and Incremental Mining:</span> Developing methods that can utilize parallel processing or handle data updates without reprocessing the entire dataset.</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Diversity of Data Types:</strong>
                                <ul class="list-disc ml-5 mt-1 space-y-1">
                                    <li><span class="font-semibold">Handling Complex Data:</span> Developing algorithms for complex data types such as time-series data, spatio-temporal data, text, multimedia, and web data.</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Security, Privacy, and Social Impacts:</strong>
                                <ul class="list-disc ml-5 mt-1 space-y-1">
                                    <li><span class="font-semibold">Data Security and Privacy:</span> Ensuring that sensitive and private data is protected during and after the mining process (e.g., data anonymization).</li>
                                    <li><span class="font-semibold">Ethical Concerns:</span> Addressing the potential for biased or discriminatory outcomes from learned models.</li>
                                </ul>
                            </li>
                        </ol>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(10)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 11 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q11">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q11">
                    <h2 class="question-title text-base font-semibold text-blue-300">11. What is OLAP? Explain the basic conceptual view of OLAP using cubes, dimensions, and measures.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">OLAP (Online Analytical Processing)</p>
                        <p class="text-sm">OLAP is a category of software technology that enables analysts and managers to gain <strong class="key-term">insight</strong> into data through fast, consistent, interactive access to a wide variety of possible views of information that has been transformed from raw data into a multidimensional structure. It is used for complex, ad-hoc, analytical queries.</p>
                        <p class="font-bold text-base mt-4 mb-1 text-blue-400">Basic Conceptual View:</p>
                        <p class="text-sm">OLAP data is organized around the <strong class="key-term">Multidimensional Data Model</strong>, which is conceptually represented as a <strong class="key-term">Data Cube</strong>.</p>
                        <ul class="list-disc ml-5 space-y-2 text-sm mt-2">
                            <li><strong class="key-term">Data Cube:</strong> A multidimensional array of data where each cell contains a measure of interest. It is formed by the intersection of multiple dimensions.</li>
                            <li><strong class="key-term">Dimensions:</strong> These are the perspectives or attributes that define a cell in the cube. They represent the axes of the cube and are used for analysis. Typical dimensions include:
                                <ul class="list-circle ml-5 mt-1 space-y-1">
                                    <li><em>Time</em> (e.g., Year, Quarter, Month)</li>
                                    <li><em>Product</em> (e.g., Product Type, Brand, Item Name)</li>
                                    <li><em>Location</em> (e.g., Country, State, City)</li>
                                    <li><em>Customer</em> (e.g., Age Group, Income Level)</li>
                                </ul>
                            </li>
                            <li><strong class="key-term">Measures (Facts):</strong> These are the numerical values that the end-user is interested in analyzing. They are the contents of the cube cells. Measures are typically additive quantities. Examples include:
                                <ul class="list-circle ml-5 mt-1 space-y-1">
                                    <li><em>Sales Amount</em></li>
                                    <li><em>Quantity Sold</em></li>
                                    <li><em>Revenue</em></li>
                                    <li><em>Profit</em></li>
                                </ul>
                            </li>
                        </ul>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(11)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 12 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q12">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q12">
                    <h2 class="question-title text-base font-semibold text-blue-300">12. List and explain the different Types of OLAP Servers (ROLAP, MOLAP, HOLAP). Compare them based on storage and performance.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="text-sm">The three main types of OLAP servers are <strong class="key-term">ROLAP</strong>, <strong class="key-term">MOLAP</strong>, and <strong class="key-term">HOLAP</strong>.</p>
                        <p class="font-bold text-sm mt-3 mb-1 text-gray-400">1. ROLAP (Relational OLAP)</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><span class="font-semibold">Explanation:</span> ROLAP servers use an extended <strong class="key-term">relational database management system (RDBMS)</strong> to store and manage warehouse data. They implement the multidimensional model using standard SQL and relational tables.</li>
                            <li><span class="font-semibold">Storage:</span> Relational Tables.</li>
                            <li><span class="font-semibold">Performance:</span> Generally <strong class="key-term">slower</strong> query performance due to complex SQL joins.</li>
                        </ul>
                        <p class="font-bold text-sm mt-3 mb-1 text-gray-400">2. MOLAP (Multidimensional OLAP)</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><span class="font-semibold">Explanation:</span> MOLAP servers use a specialized <strong class="key-term">multidimensional array-based storage engine</strong>. Data is pre-calculated and stored in proprietary array structures (cubes).</li>
                            <li><span class="font-semibold">Storage:</span> Sparse Multidimensional Arrays (Cubes).</li>
                            <li><span class="font-semibold">Performance:</span> Generally the <strong class="key-term">fastest</strong> query performance because data is pre-aggregated and retrieval uses direct indexing.</li>
                        </ul>
                        <p class="font-bold text-sm mt-3 mb-1 text-gray-400">3. HOLAP (Hybrid OLAP)</p>
                        <ul class="list-disc ml-5 space-y-1 text-sm">
                            <li><span class="font-semibold">Explanation:</span> HOLAP combines ROLAP and MOLAP. It stores summary (pre-aggregated) data in MOLAP's array format and detailed, raw data in ROLAP's relational format.</li>
                            <li><span class="font-semibold">Storage:</span> Hybrid (Summary data in Cubes, Detail data in Relational Tables).</li>
                            <li><span class="font-semibold">Performance:</span> Offers a <strong class="key-term">balance</strong> (fast for summary data, slower for drill-down to detail).</li>
                        </ul>
                        <p class="font-bold text-base mt-4 mb-1 text-blue-400">Comparison Table:</p>
                        <div class="overflow-x-auto">
                            <table class="min-w-full text-sm">
                                <thead>
                                    <tr class="bg-gray-700">
                                        <th class="p-2">Feature</th>
                                        <th class="p-2">ROLAP (Relational)</th>
                                        <th class="p-2">MOLAP (Multidimensional)</th>
                                        <th class="p-2">HOLAP (Hybrid)</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Storage Mechanism</strong></td>
                                        <td class="p-2">RDBMS (Relational Tables)</td>
                                        <td class="p-2">Specialized Array Storage (Cubes)</td>
                                        <td class="p-2">Both RDBMS and Array Storage</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Performance</strong></td>
                                        <td class="p-2">Slower (complex SQL joins)</td>
                                        <td class="p-2">Fastest (pre-calculated, direct array indexing)</td>
                                        <td class="p-2">Balanced (fast for summary, slower for detail)</td>
                                    </tr>
                                    <tr>
                                        <td class="p-2"><strong>Data Volume</strong></td>
                                        <td class="p-2">Best for very large datasets (low disk overhead)</td>
                                        <td class="p-2">Limited by cube size, potential data sparsity issues</td>
                                        <td class="p-2">Good for very large datasets</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(12)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 13 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q13">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q13">
                    <h2 class="question-title text-base font-semibold text-blue-300">13. Explain the Multidimensional Data Model with an example. Define Dimensions, Facts, and Measures.</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <p class="font-bold text-base mt-1 mb-1 text-blue-400">Multidimensional Data Model</p>
                        <p class="text-sm">The Multidimensional Data Model (MDDM) views data as organized into facts and dimensions. It is the underlying data structure used by Data Warehousing and OLAP systems. Conceptually, it is represented as a <strong class="key-term">Data Cube</strong>, where data is stored in cells defined by the coordinates of the dimensions.</p>
                        <p class="font-bold text-sm mt-3 mb-1 text-blue-400">Example (A Sales Data Cube):</p>
                        <p class="text-sm">A sales data cube could be defined by three dimensions: $\text{Time}$, $\text{Product}$, and $\text{Location}$. A cell in the cube might represent the sales data for a specific product item, in a specific city, during a specific month.</p>
                        <div class="overflow-x-auto mt-4">
                            <table class="min-w-full text-sm">
                                <thead>
                                    <tr class="bg-gray-700">
                                        <th class="p-2">Component</th>
                                        <th class="p-2">Definition</th>
                                        <th class="p-2">Example from Sales Cube</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="border-b">
                                        <td class="p-2"><strong class="key-term">Dimensions</strong></td>
                                        <td class="p-2">Categorical attributes that define the coordinates of the data (the axes of the cube). They provide the context for analytical queries.</td>
                                        <td class="p-2">$\text{Time}$ (e.g., Month, Year), $\text{Product}$ (e.g., Item Name, Brand), $\text{Location}$ (e.g., City, Country).</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2"><strong class="key-term">Facts</strong></td>
                                        <td class="p-2">The central entity of the MDDM. A fact is an event or entity for which measurements (measures) are desired.</td>
                                        <td class="p-2">A completed <em>sales transaction</em>.</td>
                                    </tr>
                                    <tr>
                                        <td class="p-2"><strong class="key-term">Measures</strong></td>
                                        <td class="p-2">The numerical, quantitative values being tracked and analyzed. They are the data points stored in the cells of the cube.</td>
                                        <td class="p-2">$\text{Sales Amount}$, $\text{Units Sold}$, $\text{Average Price}$.</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <p class="text-sm mt-2">The model supports hierarchical roll-up and drill-down operations along the dimension attributes (e.g., drilling down from 'Year' to 'Quarter' to 'Month' along the $\text{Time}$ dimension).</p>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(13)">Copy Answer</button>
                    </div>
                </div>
            </article>

            <!-- Question 14 -->
            <article class="question-card bg-gray-900 rounded-lg shadow-md border border-gray-800" id="q14">
                <div class="question-header p-4 bg-gray-800 hover:bg-gray-700 cursor-pointer flex justify-between items-center rounded-t-lg transition" data-target="q14">
                    <h2 class="question-title text-base font-semibold text-blue-300">14. Compare the Apriori Algorithm with the FP-Growth Algorithm. What is the key advantage of FP-Growth?</h2>
                    <span class="toggle-icon text-blue-300">&#9660;</span>
                </div>
                <div class="question-content p-4 border-t border-gray-800">
                    <div class="answer-text">
                        <div class="overflow-x-auto">
                            <table class="min-w-full text-sm">
                                <thead>
                                    <tr class="bg-gray-700">
                                        <th class="p-2">Feature</th>
                                        <th class="p-2">Apriori Algorithm</th>
                                        <th class="p-2">FP-Growth Algorithm</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Data Structure</strong></td>
                                        <td class="p-2">Hash Tree (for candidate counting) and Transaction Database</td>
                                        <td class="p-2"><strong class="key-term">FP-Tree (Frequent-Pattern Tree)</strong></td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Mining Approach</strong></td>
                                        <td class="p-2"><strong class="key-term">Candidate Generation &amp; Test:</strong> Uses breadth-first search. Generates candidates iteratively $C_k \to L_k$.</td>
                                        <td class="p-2"><strong class="key-term">Pattern Growth:</strong> Uses depth-first search. Compresses the database and extracts patterns recursively.</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Database Scans</strong></td>
                                        <td class="p-2"><strong class="key-term">Multiple:</strong> Requires multiple scans of the transaction database (one for each $k$-itemset level).</td>
                                        <td class="p-2"><strong class="key-term">Two:</strong> Requires only two scans of the transaction database.</td>
                                    </tr>
                                    <tr class="border-b">
                                        <td class="p-2"><strong>Performance</strong></td>
                                        <td class="p-2">Can be slow due to the large number of candidate itemsets generated, especially for dense data.</td>
                                        <td class="p-2">Highly efficient and fast, particularly for dense datasets.</td>
                                    </tr>
                                    <tr>
                                        <td class="p-2"><strong>Memory Usage</strong></td>
                                        <td class="p-2">Can be high due to storing a potentially large number of candidate itemsets.</td>
                                        <td class="p-2">Can be high to construct and store the FP-Tree structure.</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <p class="font-bold text-base mt-4 mb-1 text-blue-400">Key Advantage of FP-Growth:</p>
                        <p class="text-sm">The key advantage of the FP-Growth algorithm is that it <strong class="key-term">avoids the costly candidate generation and test process</strong> entirely. By encoding the dataset in a highly compact, prefix-tree structure called the <strong class="key-term">FP-Tree</strong>, it mines frequent itemsets directly from the tree using a divide-and-conquer (pattern growth) strategy, thereby significantly <strong class="key-term">reducing the number of database scans</strong> (from $N$ scans in Apriori to only 2) and dramatically improving performance and efficiency.</p>
                    </div>
                    <div class="action-bar pt-3 mt-3 border-t border-gray-700 flex justify-end">
                        <button class="copy-btn px-3 py-1 text-xs bg-green-600 text-white rounded-full shadow hover:bg-green-500 transition" onclick="copyAnswer(14)">Copy Answer</button>
                    </div>
                </div>
            </article>

        </section>
    </main>

    <!-- KaTeX JS and auto-render extension -->
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" crossorigin="anonymous"></script>
    <script>
        // --- 1. TOC Generation & KaTeX Initialization ---
        document.addEventListener('DOMContentLoaded', () => {
            const tocList = document.getElementById('toc');
            const sections = document.querySelectorAll('.question-card');

            sections.forEach((section, index) => {
                const questionNumber = index + 1;
                const titleElement = section.querySelector('.question-title');
                const title = titleElement ? titleElement.textContent : `Question ${questionNumber}`;
                const id = `q${questionNumber}`;
                
                section.setAttribute('id', id);

                // Create TOC link
                const listItem = document.createElement('li');
                const link = document.createElement('a');
                link.href = `#${id}`;
                link.textContent = questionNumber;
                link.setAttribute('aria-label', title);
                link.classList.add('block', 'p-2', 'text-sm', 'text-blue-400', 'hover:bg-gray-700', 'rounded-lg', 'font-medium', 'ring-1', 'ring-gray-700');

                listItem.appendChild(link);
                tocList.appendChild(listItem);
                
                // Add click listener for smooth scroll
                link.addEventListener('click', (e) => {
                    e.preventDefault();
                    document.getElementById(id).scrollIntoView({ behavior: 'smooth' });
                });

                // Set initial collapsed state
                section.classList.add('collapsed');
            });
            
            // --- KaTeX Rendering ---
            renderMathInElement(document.body, {
                delimiters: [
                    {left: '$$', right: '$$', display: true}, // Block formulas
                    {left: '$', right: '$', display: false}, // Inline formulas
                ],
                throwOnError: false
            });
        });


        // --- 2. Collapse/Expand Functionality ---
        document.addEventListener('click', (e) => {
            const header = e.target.closest('.question-header');
            if (header) {
                const section = header.parentElement;
                // Toggle the collapsed class on the question-card
                section.classList.toggle('collapsed');
                
                // Optional: Rotate arrow (already handled by CSS .collapsed .toggle-icon)
            }
        });


        // --- 3. Copy Functionality ---
        function copyAnswer(qNum) {
            const section = document.getElementById(`q${qNum}`);
            const answerTextDiv = section.querySelector('.answer-text');
            
            let textToCopy = answerTextDiv.innerText || answerTextDiv.textContent;
            
            // Use modern API with fallback
            if (navigator.clipboard) {
                navigator.clipboard.writeText(textToCopy).then(() => {
                    alert('Answer copied to clipboard!');
                }).catch(err => {
                    fallbackCopy(textToCopy);
                });
            } else {
                fallbackCopy(textToCopy);
            }
        }
        
        // Fallback for document.execCommand('copy')
        function fallbackCopy(text) {
            const tempTextArea = document.createElement('textarea');
            tempTextArea.value = text;
            tempTextArea.style.position = 'fixed'; 
            document.body.appendChild(tempTextArea);
            tempTextArea.select();
            
            try {
                document.execCommand('copy');
                alert('Answer copied to clipboard!');
            } catch (err) {
                alert('Copying failed. Please copy manually.');
            }
            document.body.removeChild(tempTextArea);
        }

        // --- 4. Search and Highlight Functionality ---
        let lastSearchTerm = '';
        function highlightText(searchTerm) {
            const notesContainer = document.getElementById('notes-container');
            const cleanHtml = notesContainer.innerHTML.replace(/<span class="highlight">(.*?)<\/span>/g, '$1');
            notesContainer.innerHTML = cleanHtml;
            
            lastSearchTerm = searchTerm.trim().toLowerCase();
            
            if (lastSearchTerm.length < 2) {
                return;
            }

            const textNodes = [];
            const walk = document.createTreeWalker(notesContainer, NodeFilter.SHOW_TEXT, null, false);
            let node;

            while (node = walk.nextNode()) {
                // Exclude script, style, and content inside KaTeX containers (to prevent breaking formulas)
                if (node.parentElement.tagName !== 'SCRIPT' && 
                    node.parentElement.tagName !== 'STYLE' && 
                    node.parentElement.className.indexOf('highlight') === -1 &&
                    !node.parentElement.closest('.katex')) { 
                    textNodes.push(node);
                }
            }
            
            textNodes.forEach(node => {
                const content = node.nodeValue;
                const lowerContent = content.toLowerCase();
                let lastIndex = 0;
                const fragments = [];
                let matchCount = 0;
                
                for (let i = 0; i <= lowerContent.length; i++) {
                    const matchIndex = lowerContent.indexOf(lastSearchTerm, i);
                    if (matchIndex === -1) break;

                    if (matchIndex > lastIndex) {
                        fragments.push(document.createTextNode(content.substring(lastIndex, matchIndex)));
                    }

                    const highlightedText = content.substring(matchIndex, matchIndex + lastSearchTerm.length);
                    const highlightSpan = document.createElement('span');
                    highlightSpan.className = 'highlight';
                    highlightSpan.textContent = highlightedText;
                    fragments.push(highlightSpan);

                    lastIndex = matchIndex + lastSearchTerm.length;
                    i = lastIndex - 1; 
                    matchCount++;
                }

                if (lastIndex < content.length) {
                    fragments.push(document.createTextNode(content.substring(lastIndex)));
                }

                if (matchCount > 0) {
                    const parent = node.parentNode;
                    if (parent) {
                        fragments.forEach(fragment => parent.insertBefore(fragment, node));
                        parent.removeChild(node);
                    }
                }
            });
        }
    </script>
</body>
</html>
